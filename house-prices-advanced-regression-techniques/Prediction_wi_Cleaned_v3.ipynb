{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## memo try function based munging next time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "train_df.head()\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are a few houses with more than 4000 sq ft living area that are\n",
    "# outliers, so we drop them from the training data. (There is also one in\n",
    "# the test set but we obviously can't drop that one.)\n",
    "train_df.drop(train_df[train_df['GrLivArea'] > 4000].index, inplace=True)\n",
    "\n",
    "# The test example with ID 666 has GarageArea, GarageCars, and GarageType \n",
    "# but none of the other fields, so use the mode and median to fill them in.\n",
    "test_df.loc[666, 'GarageQual'] = 'TA'\n",
    "test_df.loc[666, 'GarageCond'] = 'TA'\n",
    "test_df.loc[666, 'GarageFinish'] = 'Unf'\n",
    "test_df.loc[666, 'GarageYrBlt'] = 1980\n",
    "\n",
    "# The test example 1116 only has GarageType but no other information. We'll \n",
    "# assume it does not have a garage.\n",
    "test_df.loc[1116, 'GarageType'] = np.nan\n",
    "\n",
    "# For imputing missing values: fill in missing LotFrontage values by the median\n",
    "# LotFrontage of the neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig      ...       ScreenPorch PoolArea PoolQC  \\\n",
       "0         Lvl    AllPub    Inside      ...                 0        0    NaN   \n",
       "1         Lvl    AllPub       FR2      ...                 0        0    NaN   \n",
       "2         Lvl    AllPub    Inside      ...                 0        0    NaN   \n",
       "3         Lvl    AllPub    Corner      ...                 0        0    NaN   \n",
       "4         Lvl    AllPub       FR2      ...                 0        0    NaN   \n",
       "\n",
       "  Fence MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0   NaN         NaN       0       2    2008        WD         Normal  \n",
       "1   NaN         NaN       0       5    2007        WD         Normal  \n",
       "2   NaN         NaN       0       9    2008        WD         Normal  \n",
       "3   NaN         NaN       0       2    2006        WD        Abnorml  \n",
       "4   NaN         NaN       0      12    2008        WD         Normal  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the data and take all of the feature. This is for easier feature engineering. \n",
    "all_data = pd.concat((train_df.iloc[:,1:-1], test_df.iloc[:,1:]), axis = 0)\n",
    "Y = np.log(train_df[\"SalePrice\"])\n",
    "\n",
    "# remember the length of train data\n",
    "trainLen = len(train_df)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There is a na TotalBsmtSF value in the test set for \n",
    "all_data.loc[all_data[\"TotalBsmtSF\"].isnull(),'TotalBsmtSF'] = 0\n",
    "\n",
    "# Add a variable for total living area\n",
    "all_data['TotalLivArea'] = all_data['GrLivArea'] + all_data['TotalBsmtSF'] + all_data['GarageArea']\n",
    "\n",
    "# Add a variable for total porch Area\n",
    "all_data['TotalPorchSF'] = all_data[['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill in missing values\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(all_data.loc[all_data['LotFrontage'].notnull(), ['LotArea']],\n",
    "        all_data.loc[all_data['LotFrontage'].notnull(), ['LotFrontage']])\n",
    "all_data.loc[all_data['LotFrontage'].isnull(), ['LotFrontage']] = reg.predict(\n",
    "    all_data.loc[all_data['LotFrontage'].isnull(), ['LotArea']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add some feature\n",
    "all_data['IsRegularLotShape'] = (all_data['LotShape'] == 'Reg') * 1\n",
    "all_data['IsLandLevel'] = (all_data['LandContour'] == 'Lv1') * 1\n",
    "all_data['IsLandSlopeGentle'] = (all_data['LandSlope'] == 'Gtl') * 1\n",
    "all_data['IsElectricalBrkr'] = (all_data['Electrical'] == 'SBrkr') * 1\n",
    "all_data['IsGarageDetached'] = (all_data['GarageType'] == 'Detchd') * 1\n",
    "all_data['IsPavedDrive'] = (all_data['PavedDrive'] == 'Y') * 1\n",
    "all_data['HasShed'] = (all_data['MiscFeature'] == 'Shed') * 1\n",
    "all_data['Remodeled'] = (all_data['YearRemodAdd'] != all_data['YearBuilt']) * 1\n",
    "all_data['RecentRemodel'] = (all_data['YearRemodAdd'] == all_data['YearBuilt']) * 1\n",
    "all_data['VeryNewHouse'] = (all_data['YearBuilt'] == all_data['YrSold']) * 1\n",
    "all_data['Has2ndFloor'] = (all_data['2ndFlrSF'] > 0) * 1\n",
    "all_data['HasMasVnr'] = (all_data['MasVnrArea'] > 0) * 1\n",
    "all_data['HasWoodDeck'] = (all_data['WoodDeckSF'] > 0) * 1\n",
    "all_data['HasOpenPorch'] = (all_data['OpenPorchSF'] > 0) * 1\n",
    "all_data['HasEnclosedPorch'] = (all_data['EnclosedPorch'] > 0) * 1\n",
    "all_data['Has3SsnPorch'] = (all_data['3SsnPorch'] > 0) * 1\n",
    "all_data['HasScreenPorch'] = (all_data['ScreenPorch'] > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qual_dict = {None: 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'NA' : 0}\n",
    "QualFeats = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', \n",
    "             'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "for feat in QualFeats:\n",
    "    all_data[feat + '_Quant'] = all_data[feat].map(qual_dict).astype(int)\n",
    "\n",
    "all_data['LotShape_Quant'] = all_data['LotShape'].replace([None, 'IR3','IR2','IR1' ,'Reg'], [0,1,2,3,4])\n",
    "all_data['LandContour_Quant'] = all_data['LandContour'].replace([None, 'Low', 'HLS', 'Bnk','Lvl'], [0,1,2,3,4])\n",
    "all_data['Utilities_Quant'] = all_data['Utilities'].replace([None, 'ELO','NoSeWa','NoSewr','AllPub'], [0,1,2,3,4])\n",
    "all_data['LandSlope_Quant'] = all_data['LandSlope'].replace([None, 'Sev' , 'Mod', 'Gtl'], [0,1,2,3])\n",
    "all_data['BsmtExposure_Quant'] = all_data['BsmtExposure'].replace([None, 'No', 'Mn', 'Av', 'Gd'], [0,1,2,3,4])\n",
    "all_data['BsmtFinType1_Quant'] = all_data['BsmtFinType1'].replace([None, 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'], [0,1,2,3,4,5,6])\n",
    "all_data['BsmtFinType2_Quant'] = all_data['BsmtFinType2'].replace([None, 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'], [0,1,2,3,4,5,6])\n",
    "all_data['Functional_Quant'] = all_data['Functional'].replace([None, 'Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'], [\n",
    "        0,1,2,3,4,5,6,7,8])\n",
    "all_data['GarageFinish_Quant'] = all_data['GarageFinish'].replace([None, 'Unf', 'RFn', 'Fin'], [0,1,2,3])\n",
    "all_data['Fence_Quant'] = all_data['Fence'].replace([None, 'MnWw', 'GdWo', 'MnPrv', 'GdPrv'], [0,1,2,3,4])\n",
    "all_data['CentralAir_Quant'] = all_data['CentralAir'].replace([None,'N','Y'], [0,0,1])\n",
    "all_data['NewerDwelling'] = all_data['MSSubClass'].map({20: 1, 30: 0, 40: 0, 45: 0,50: 0, 60: 1,\n",
    "                                                        70: 0, 75: 0, 80: 0, 85: 0, 90: 0, 120: 1,\n",
    "                                                        150: 0, 160: 0, 180: 0, 190: 0}).astype(int)\n",
    "all_data['GoodNeighborhood'] = 0\n",
    "all_data['GoodNeighborhood'] = ((all_data['Neighborhood'] == 'NridgHt') | \n",
    "                                (all_data['Neighborhood'] == 'Crawfor') |\n",
    "                                (all_data['Neighborhood'] == 'StoneBr') |\n",
    "                                (all_data['Neighborhood'] == 'Somerst') |\n",
    "                                (all_data['Neighborhood'] == 'NoRidge')) * 1\n",
    "all_data['SaleCondition_PriceDown'] = all_data['SaleCondition'].replace(\n",
    "        {'Abnorml': 1, 'Alloca': 2, 'AdjLand': 3, 'Family': 4, 'Normal': 5, 'Partial': 0})\n",
    "all_data['BoughtOffPlan'] = all_data['SaleCondition'].replace(\n",
    "        {'Abnorml' : 0, 'Alloca' : 0, 'AdjLand' : 0, 'Family' : 0, 'Normal' : 0, 'Partial' : 1})\n",
    "\n",
    "\n",
    "\n",
    "all_data['MSZoning'].fillna('RL', inplace=True)\n",
    "all_data['Exterior1st'].fillna('Other', inplace=True)\n",
    "all_data['Exterior2nd'].fillna('Other', inplace=True)\n",
    "all_data['MasVnrType'].fillna('None', inplace=True)\n",
    "all_data['SaleType'].fillna('Oth', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's add time interval in year between build and sold time.\n",
    "all_data['Age'] = 2010 -  all_data['YearBuilt']\n",
    "all_data['TimeSinceSold'] = 2010 -  all_data['YearRemodAdd']\n",
    "all_data['BltYears'] = all_data['YrSold'] -  all_data['YearBuilt']\n",
    "all_data['RemYears'] = all_data['YrSold'] -  all_data['YearRemodAdd']\n",
    "all_data['GaBltyears'] = all_data['YrSold'] -  all_data['GarageYrBlt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MoSold seems more like a categorical data, let's check the distribution\n",
    "# sns.boxplot(y = Y, x = all_data[:trainLen]['MoSold'])\n",
    "all_data['HighSeason'] = all_data['MoSold'].map({1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, \n",
    "                                                 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0}).astype(int)\n",
    "all_data['SeasonSold'] = all_data['MoSold'].map({12:0, 1:0, 2:0, 3:1, 4:1, 5:1, \n",
    "                                                  6:2, 7:2, 8:2, 9:3, 10:3, 11:3}).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary district\n",
    "neighborhood_map = {\n",
    "        'MeadowV' : 0,  #  88000\n",
    "        'IDOTRR' : 1,   # 103000\n",
    "        'BrDale' : 1,   # 106000\n",
    "        'OldTown' : 1,  # 119000\n",
    "        'Edwards' : 1,  # 119500\n",
    "        'BrkSide' : 1,  # 124300\n",
    "        'Sawyer' : 1,   # 135000\n",
    "        'Blueste' : 1,  # 137500\n",
    "        'SWISU' : 2,    # 139500\n",
    "        'NAmes' : 2,    # 140000\n",
    "        'NPkVill' : 2,  # 146000\n",
    "        'Mitchel' : 2,  # 153500\n",
    "        'SawyerW' : 2,  # 179900\n",
    "        'Gilbert' : 2,  # 181000\n",
    "        'NWAmes' : 2,   # 182900\n",
    "        'Blmngtn' : 2,  # 191000\n",
    "        'CollgCr' : 2,  # 197200\n",
    "        'ClearCr' : 3,  # 200250\n",
    "        'Crawfor' : 3,  # 200624\n",
    "        'Veenker' : 3,  # 218000\n",
    "        'Somerst' : 3,  # 225500\n",
    "        'Timber' : 3,   # 228475\n",
    "        'StoneBr' : 4,  # 278000\n",
    "        'NoRidge' : 4,  # 290000\n",
    "        'NridgHt' : 4,  # 315000\n",
    "}\n",
    "\n",
    "all_data['NeighborhoodBin'] = all_data['Neighborhood'].map(neighborhood_map).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              nullNums DataType\n",
      "GaBltyears         158  float64\n",
      "TotalLivArea         1  float64\n",
      "BsmtHalfBath         2  float64\n",
      "BsmtFullBath         2  float64\n",
      "GarageCars           1  float64\n",
      "BsmtUnfSF            1  float64\n",
      "BsmtFinSF2           1  float64\n",
      "GarageArea           1  float64\n",
      "MasVnrArea          23  float64\n",
      "BsmtFinSF1           1  float64\n",
      "GarageYrBlt        158  float64\n",
      "GarageFinish       158   object\n",
      "GarageQual         158   object\n",
      "GarageCond         158   object\n",
      "PoolQC            2907   object\n",
      "Fence             2345   object\n",
      "MiscFeature       2810   object\n",
      "Alley             2717   object\n",
      "FireplaceQu       1420   object\n",
      "Functional           2   object\n",
      "Electrical           1   object\n",
      "BsmtFinType2        80   object\n",
      "BsmtFinType1        79   object\n",
      "BsmtExposure        82   object\n",
      "BsmtCond            82   object\n",
      "BsmtQual            81   object\n",
      "Utilities            2   object\n",
      "GarageType         158   object\n",
      "KitchenQual          1   object\n"
     ]
    }
   ],
   "source": [
    "# check na value count\n",
    "nullCnt = pd.DataFrame({'nullNums' : all_data.isnull().sum()})\n",
    "nullCnt['DataType'] = all_data[nullCnt.index].dtypes\n",
    "print nullCnt[nullCnt['nullNums'] > 0].sort_values(by = 'DataType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill numerical na with 0, category na with 'None'\n",
    "numeric_feature = all_data.columns[all_data.dtypes != 'object']\n",
    "all_data[numeric_feature] = all_data[numeric_feature].fillna(0)\n",
    "\n",
    "category_feature = all_data.columns[all_data.dtypes == 'object']\n",
    "all_data[category_feature] = all_data[category_feature].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['MoSold_Cate'] = all_data['MoSold'].astype('category')\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_feature = all_data.columns[(all_data.dtypes != 'object') & (all_data.dtypes != 'category')]\n",
    "skewed_feats = all_data[numeric_feature].apply(lambda x: skew(x[x > 0].astype(float)))\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.9].index\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Additional processing: scale the data.   \n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_data[numeric_feature])\n",
    "\n",
    "all_data.loc[:, numeric_feature] = scaler.transform(all_data[numeric_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There're several pairs of feature that should be merged when one-hot encoded\n",
    "\n",
    "# Deal with Exterior\n",
    "for name in all_data[\"Exterior1st\"].dropna().unique():\n",
    "    all_data[\"Exterior\" + \"-\" + name] = 1 * ((all_data[\"Exterior1st\"] == name) | (all_data[\"Exterior2nd\"] == name))\n",
    "\n",
    "# Deal with Condition\n",
    "for name in all_data[\"Condition1\"].dropna().unique():\n",
    "    all_data[\"Condition\" + \"-\" + name] = 1 * ((all_data[\"Condition1\"] == name) | (all_data[\"Condition2\"] == name))\n",
    "    \n",
    "all_data = all_data.drop(['Exterior1st','Exterior2nd'], axis=1)\n",
    "all_data = all_data.drop(['Condition1','Condition2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2915, 361)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encode category data\n",
    "all_data = pd.get_dummies(all_data)\n",
    "all_data.shape\n",
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1456, 361), (1459, 361))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Several types of features should be avoid.\n",
    "# 1. All zero feature in either train set or test set\n",
    "# 2. Extremely sparse features\n",
    "trainShape = all_data[:trainLen].shape\n",
    "testShape = all_data[trainLen:].shape\n",
    "trainShape, testShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop low variance candidates\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(0 * (1 - 0)))\n",
    "sel.fit(all_data[:trainLen])\n",
    "train_feats = sel.get_support()\n",
    "sel.fit(all_data[trainLen:])\n",
    "test_feats = sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = all_data.loc[:, train_feats & test_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2915, 344)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = all_data[:trainLen]\n",
    "X_test  = all_data[trainLen:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Regularized model\n",
    "Same as before try both ridge and lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn import model_selection, metrics   #Additional scklearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.1111355571460618, {'alpha': 0.0002}),\n",
       "  (0.10892105240246958, {'alpha': 0.0005}),\n",
       "  (0.10931306187247626, {'alpha': 0.001}),\n",
       "  (0.11511128694902441, {'alpha': 0.005}),\n",
       "  (0.11934623731003474, {'alpha': 0.01}),\n",
       "  (0.15775502473448547, {'alpha': 0.05})],\n",
       " {'alpha': 0.0005},\n",
       " 0.10892105240246958)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_param_test = {\n",
    "    'alpha':[0.0002,0.0005,0.001,0.005,0.01,0.05]\n",
    "#     'alpha': np.arange(0.0002,0.0007,0.00005)\n",
    "}\n",
    "\n",
    "lasso_search = GridSearchCV(\n",
    "    estimator = Lasso(max_iter = 10000),\n",
    "    param_grid = lasso_param_test, \n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=4,\n",
    "    iid=False, \n",
    "    cv=5\n",
    ")\n",
    "lasso_search.fit(X_train,Y)\n",
    "zip(np.sqrt(-lasso_search.cv_results_['mean_test_score']),lasso_search.cv_results_['params']), lasso_search.best_params_,np.sqrt(- lasso_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before LASSO works better. Let's take a look at the top features first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.11319861710467638, {'reg_alpha': 0.0001, 'reg_lambda': 0.001}),\n",
       "  (0.11308659679927889, {'reg_alpha': 0.0001, 'reg_lambda': 0.005}),\n",
       "  (0.11349974314414901, {'reg_alpha': 0.0001, 'reg_lambda': 0.01}),\n",
       "  (0.11384893478982977, {'reg_alpha': 0.0001, 'reg_lambda': 0.05}),\n",
       "  (0.11518235258281116, {'reg_alpha': 0.0001, 'reg_lambda': 0.1}),\n",
       "  (0.11740754442979882, {'reg_alpha': 0.0001, 'reg_lambda': 0.5}),\n",
       "  (0.11717870661418714, {'reg_alpha': 0.0001, 'reg_lambda': 1}),\n",
       "  (0.11689497069836971, {'reg_alpha': 0.0001, 'reg_lambda': 3}),\n",
       "  (0.11684925931108561, {'reg_alpha': 0.0001, 'reg_lambda': 10}),\n",
       "  (0.11316236516284806, {'reg_alpha': 0.0005, 'reg_lambda': 0.001}),\n",
       "  (0.11311912999353588, {'reg_alpha': 0.0005, 'reg_lambda': 0.005}),\n",
       "  (0.11398938147372378, {'reg_alpha': 0.0005, 'reg_lambda': 0.01}),\n",
       "  (0.11388538153360214, {'reg_alpha': 0.0005, 'reg_lambda': 0.05}),\n",
       "  (0.11493284909429179, {'reg_alpha': 0.0005, 'reg_lambda': 0.1}),\n",
       "  (0.1175859180264322, {'reg_alpha': 0.0005, 'reg_lambda': 0.5}),\n",
       "  (0.11694522912283564, {'reg_alpha': 0.0005, 'reg_lambda': 1}),\n",
       "  (0.11682385559431645, {'reg_alpha': 0.0005, 'reg_lambda': 3}),\n",
       "  (0.11690628236024403, {'reg_alpha': 0.0005, 'reg_lambda': 10}),\n",
       "  (0.11328639483577253, {'reg_alpha': 0.001, 'reg_lambda': 0.001}),\n",
       "  (0.11314332151224502, {'reg_alpha': 0.001, 'reg_lambda': 0.005}),\n",
       "  (0.11378171192987359, {'reg_alpha': 0.001, 'reg_lambda': 0.01}),\n",
       "  (0.11405936992778022, {'reg_alpha': 0.001, 'reg_lambda': 0.05}),\n",
       "  (0.11502130451729622, {'reg_alpha': 0.001, 'reg_lambda': 0.1}),\n",
       "  (0.11656027387513349, {'reg_alpha': 0.001, 'reg_lambda': 0.5}),\n",
       "  (0.11711354657214421, {'reg_alpha': 0.001, 'reg_lambda': 1}),\n",
       "  (0.11718159270642849, {'reg_alpha': 0.001, 'reg_lambda': 3}),\n",
       "  (0.1170923644496201, {'reg_alpha': 0.001, 'reg_lambda': 10}),\n",
       "  (0.11381646061199022, {'reg_alpha': 0.005, 'reg_lambda': 0.001}),\n",
       "  (0.11288220667816758, {'reg_alpha': 0.005, 'reg_lambda': 0.005}),\n",
       "  (0.11401267112721621, {'reg_alpha': 0.005, 'reg_lambda': 0.01}),\n",
       "  (0.11454134528930228, {'reg_alpha': 0.005, 'reg_lambda': 0.05}),\n",
       "  (0.11573889513641093, {'reg_alpha': 0.005, 'reg_lambda': 0.1}),\n",
       "  (0.1160912705709926, {'reg_alpha': 0.005, 'reg_lambda': 0.5}),\n",
       "  (0.11691644285779014, {'reg_alpha': 0.005, 'reg_lambda': 1}),\n",
       "  (0.11779847832548716, {'reg_alpha': 0.005, 'reg_lambda': 3}),\n",
       "  (0.11683554718846775, {'reg_alpha': 0.005, 'reg_lambda': 10}),\n",
       "  (0.11295038041674425, {'reg_alpha': 0.01, 'reg_lambda': 0.001}),\n",
       "  (0.11296340755801014, {'reg_alpha': 0.01, 'reg_lambda': 0.005}),\n",
       "  (0.11434697554829042, {'reg_alpha': 0.01, 'reg_lambda': 0.01}),\n",
       "  (0.11440279934594781, {'reg_alpha': 0.01, 'reg_lambda': 0.05}),\n",
       "  (0.11542927015549044, {'reg_alpha': 0.01, 'reg_lambda': 0.1}),\n",
       "  (0.11577357884989767, {'reg_alpha': 0.01, 'reg_lambda': 0.5}),\n",
       "  (0.11717080116723511, {'reg_alpha': 0.01, 'reg_lambda': 1}),\n",
       "  (0.11789334338143662, {'reg_alpha': 0.01, 'reg_lambda': 3}),\n",
       "  (0.11700721833526018, {'reg_alpha': 0.01, 'reg_lambda': 10}),\n",
       "  (0.11317527868917363, {'reg_alpha': 0.05, 'reg_lambda': 0.001}),\n",
       "  (0.1136999721746505, {'reg_alpha': 0.05, 'reg_lambda': 0.005}),\n",
       "  (0.11415214091688305, {'reg_alpha': 0.05, 'reg_lambda': 0.01}),\n",
       "  (0.11484829646936617, {'reg_alpha': 0.05, 'reg_lambda': 0.05}),\n",
       "  (0.11644737582226698, {'reg_alpha': 0.05, 'reg_lambda': 0.1}),\n",
       "  (0.11629358588272765, {'reg_alpha': 0.05, 'reg_lambda': 0.5}),\n",
       "  (0.11708814125075585, {'reg_alpha': 0.05, 'reg_lambda': 1}),\n",
       "  (0.11816189582723213, {'reg_alpha': 0.05, 'reg_lambda': 3}),\n",
       "  (0.1171860531708652, {'reg_alpha': 0.05, 'reg_lambda': 10})],\n",
       " {'reg_alpha': 0.005, 'reg_lambda': 0.005},\n",
       " 0.11288220667816758)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All tuning would be done within this cell\n",
    "xgb_param_test = {\n",
    "#     'max_depth':range(3,10,3),\n",
    "#     'min_child_weight':range(1,8,2)\n",
    "#     'gamma' : [0.0005, 0.001,0.005,0.01,0.05,0.1]\n",
    "#     'gamma' : np.arange(0.003, 0.01, 0.0005)\n",
    "#     'subsample': np.arange(0.1,1,0.2),\n",
    "#     'colsample_bytree': np.arange(0.1,1,0.2),\n",
    "#     'subsample': np.arange(0.4,0.6,0.04),\n",
    "#     'colsample_bytree': np.arange(0.8,1,0.04),\n",
    "    'reg_alpha' : [0.0001,0.0005,0.001,0.005,0.01,0.05],\n",
    "    'reg_lambda' : [0.001,0.005,0.01,0.05,0.1,0.5,1,3,10]\n",
    "#     'reg_alpha' : np.arange(7e-6,9e-6,3e-7) # 8.2e-6\n",
    "#     'reg_lambda' : np.arange(0.7,1.1,0.03)\n",
    "}\n",
    "xgb_search = GridSearchCV(\n",
    "    estimator = XGBRegressor(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=140,\n",
    "        max_depth=3,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.005,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.3,\n",
    "        objective= 'reg:linear',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        reg_alpha = 0.005,\n",
    "        reg_lambda = 0.005,        \n",
    "        seed=100\n",
    "    ),\n",
    "    param_grid = xgb_param_test,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    n_jobs = 1,\n",
    "    iid = False,\n",
    "    cv = 5\n",
    ")\n",
    "xgb_search.fit(X_train, Y)\n",
    "zip(np.sqrt(-xgb_search.cv_results_['mean_test_score']),xgb_search.cv_results_['params']), xgb_search.best_params_,np.sqrt(- xgb_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "model_lasso = Lasso(alpha = 0.0005, max_iter = 50000)\n",
    "model_xgb = XGBRegressor( # use all features\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=5000,\n",
    "    max_depth=3,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.01,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.3,\n",
    "    objective= 'reg:linear',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    reg_alpha = 0.005,\n",
    "    reg_lambda = 0.005, \n",
    "    seed=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lasso_1</th>\n",
       "      <th>Xgb_1</th>\n",
       "      <th>Lasso_2</th>\n",
       "      <th>Xgb_2</th>\n",
       "      <th>Lasso_3</th>\n",
       "      <th>Xgb_3</th>\n",
       "      <th>Lasso_4</th>\n",
       "      <th>Xgb_4</th>\n",
       "      <th>Lasso_5</th>\n",
       "      <th>Xgb_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123029.099069</td>\n",
       "      <td>130193.023438</td>\n",
       "      <td>123965.674301</td>\n",
       "      <td>131800.203125</td>\n",
       "      <td>122162.774977</td>\n",
       "      <td>130005.304688</td>\n",
       "      <td>125169.398832</td>\n",
       "      <td>134009.375000</td>\n",
       "      <td>122732.051415</td>\n",
       "      <td>129670.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152447.086669</td>\n",
       "      <td>155931.109375</td>\n",
       "      <td>150675.945690</td>\n",
       "      <td>160202.781250</td>\n",
       "      <td>152428.100069</td>\n",
       "      <td>157354.437500</td>\n",
       "      <td>152265.035783</td>\n",
       "      <td>152372.718750</td>\n",
       "      <td>152989.591729</td>\n",
       "      <td>153003.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>179837.083944</td>\n",
       "      <td>184983.203125</td>\n",
       "      <td>182815.728922</td>\n",
       "      <td>186337.343750</td>\n",
       "      <td>176837.987280</td>\n",
       "      <td>188354.296875</td>\n",
       "      <td>176839.281491</td>\n",
       "      <td>186370.046875</td>\n",
       "      <td>180338.432921</td>\n",
       "      <td>193164.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196528.202382</td>\n",
       "      <td>199833.203125</td>\n",
       "      <td>196887.069518</td>\n",
       "      <td>196749.156250</td>\n",
       "      <td>196214.581294</td>\n",
       "      <td>193698.656250</td>\n",
       "      <td>192684.056586</td>\n",
       "      <td>194015.171875</td>\n",
       "      <td>194788.109483</td>\n",
       "      <td>199242.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197185.702364</td>\n",
       "      <td>182855.812500</td>\n",
       "      <td>196766.023775</td>\n",
       "      <td>178076.187500</td>\n",
       "      <td>196597.795574</td>\n",
       "      <td>177957.187500</td>\n",
       "      <td>200147.729911</td>\n",
       "      <td>184053.906250</td>\n",
       "      <td>197198.146859</td>\n",
       "      <td>189413.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lasso_1          Xgb_1        Lasso_2          Xgb_2        Lasso_3  \\\n",
       "0  123029.099069  130193.023438  123965.674301  131800.203125  122162.774977   \n",
       "1  152447.086669  155931.109375  150675.945690  160202.781250  152428.100069   \n",
       "2  179837.083944  184983.203125  182815.728922  186337.343750  176837.987280   \n",
       "3  196528.202382  199833.203125  196887.069518  196749.156250  196214.581294   \n",
       "4  197185.702364  182855.812500  196766.023775  178076.187500  196597.795574   \n",
       "\n",
       "           Xgb_3        Lasso_4          Xgb_4        Lasso_5          Xgb_5  \n",
       "0  130005.304688  125169.398832  134009.375000  122732.051415  129670.859375  \n",
       "1  157354.437500  152265.035783  152372.718750  152989.591729  153003.078125  \n",
       "2  188354.296875  176839.281491  186370.046875  180338.432921  193164.984375  \n",
       "3  193698.656250  192684.056586  194015.171875  194788.109483  199242.531250  \n",
       "4  177957.187500  200147.729911  184053.906250  197198.146859  189413.125000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "idxcnt = 1\n",
    "result = pd.DataFrame({'dummy' : test_df.Id})\n",
    "result['dummy'] = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    model_lasso.fit(X_train.iloc[train_index,:], Y.iloc[train_index])\n",
    "    model_xgb.fit(X_train.iloc[train_index,:], Y.iloc[train_index])\n",
    "    res_lasso = pd.DataFrame({'Lasso_' + str(idxcnt) : np.exp(model_lasso.predict(X_test))})\n",
    "    res_xgb   = pd.DataFrame({'Xgb_' + str(idxcnt)   : np.exp(model_xgb.predict(X_test))})\n",
    "    result = pd.concat((result, res_lasso, res_xgb), axis = 1)\n",
    "    idxcnt += 1\n",
    "result = result.drop('dummy', axis = 1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame({'Id' : test_df.Id, 'SalePrice' : result.mean(axis = 1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_result.to_csv(\"final_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
